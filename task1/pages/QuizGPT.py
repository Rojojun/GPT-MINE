import streamlit as st
from langchain.retrievers import WikipediaRetriever
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks import StreamingStdOutCallbackHandler

st.set_page_config(
    page_title="QuizGPT",
    page_icon="ğŸ™‹"
)

st.title("QuizGPT")

llm = ChatOpenAI(
    temperature=0.1,
    model="gpt-3.5-turbo-1106",
    streaming=True,
    callbacks=[
        StreamingStdOutCallbackHandler()
    ]
)

@st.cache_data(show_spinner="Loading file...")
def split_file(file):
    file_content = file.read()
    file_path = f"./.cache/quiz_files/{file.name}"
    with open(file_path, "wb") as f:
        f.write(file_content)
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )
    loader = UnstructuredFileLoader(file_path)
    docs = loader.load_and_split(text_splitter=splitter)
    return docs

def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)

with st.sidebar:
    docs = None
    choice = st.selectbox(
        "ì„ íƒ",
        (
            "File",
            "Wikipedia Article",
        ),
    )
    if choice == "File":
        file = st.file_uploader(
            ".docx , .txt , .pdf file",
            type=["pdf", "txt", "docx"],
        )
        if file:
            docs = split_file(file)
            st.write(docs)
    else:
        topic = st.text_input("ìœ„í‚¤ ê²€ìƒ‰ ì¤‘...")
        if topic:
            retriever = WikipediaRetriever(top_k_results=5)
            with st.status("ìœ„í‚¤ ê²€ìƒ‰ ì¤‘..."):
                docs = retriever.get_relevant_documents(topic)
if not docs:
    st.markdown(
        """
        í .. ì•ˆë…•...
        ì´ê±´ í•„ìš” ì—†ë‹¤.
        """
    )
else:
    st.write(docs)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
                ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œë§Œ ëŒ€ë‹µì„ í•©ë‹ˆë‹¤.
                ë‹¹ì‹ ì€ ì„ ìƒë‹˜ì„ ë„ì™€ì£¼ëŠ” í›Œë¥­í•œ ì¡°ìˆ˜ ì¸ê³µì§€ëŠ¥ì…ë‹ˆë‹¤.
                ì´ë¦„ë„ ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì™ˆì™ˆì´ì…ë‹ˆë‹¤. ëˆ„ê°€ ë‹¹ì‹ ì˜ ì´ë¦„ì„ ë¬¼ì–´ë³¼ë•Œ ì™ˆì™ˆì´ë¼ê³  ëŒ€ë‹µí•˜ë©´ ë©ë‹ˆë‹¤.

                ë‹¹ì‹ ì€ ìœ ì €ì˜ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì§€ì‹ì„ íŒë‹¨í•˜ëŠ” ë¬¸ì œ 6ê°œë¥¼ ë§Œë“¤ê³  ê´€ê³„ ì—†ëŠ” ë‚œí•´í•œ ì§ˆë¬¸ë„ í•©ë‹ˆë‹¤.
                ê°ê°ì˜ ì§ˆë¬¸ë“¤ì€ ë‹¤ì–‘í•œ ë‚œì´ë„ë¥¼ í¬í•¨í•´ì•¼í•©ë‹ˆë‹¤.

                ë‚œí•´í•œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                ì˜ˆë¥¼ ë“¤ì–´ì„œ ë‚œí•´í•œ ì§ˆë¬¸ì€ ì´ëŸ° ê²ë‹ˆë‹¤.

                ì§ˆë¬¸ : ìë™ì°¨ê°€ ë†€ë¼ë©´?
                ëŒ€ë‹µ : ì¹´ë†€ë¼ìœ 

                ì§ˆë¬¸ : ì¥êµ°ë“¤ì´ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€?
                ëŒ€ë‹µ : íŒŒìŠ¤íƒ€

                ì§ˆë¬¸ : í‹°ëª¨ëŠ” ì™œ ë¶€ì‰¬ì— ìˆ¨ì–´ìˆì„ê¹Œ?
                ëŒ€ë‹µ : ìƒ¤ì½”í•œí…Œ ë§ê¸° ì‹«ì–´ì„œ

                ì§ˆë¬¸ : ì„¸ìƒì—ì„œ ì œì¼ ì˜ˆìœ ë™ë¬¼ì€?
                ëŒ€ë‹µ : ê¿¿ëš«ê¿¿ì’§ë›Ÿ

                ì ì´ì œ ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”
                
                Context:{context}
                """
            )
        ]
    )

    chain = prompt | llm

    start = st.button("í€´ì¦ˆ ìƒì„±ê¸°")

    if start:
        chain.invoke(docs)